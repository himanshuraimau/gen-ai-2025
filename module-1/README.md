# Module 1: Foundations of LLMs & Generative AI

## Overview
This module establishes the foundation for working with Large Language Models and generative AI technologies.

## Learning Objectives
- Understand how LLMs work and their capabilities
- Learn effective prompt engineering techniques
- Set up a proper development environment
- Build your first LLM-powered applications

## Tasks

### Task 1: Setup Development Environment
- Install Python 3.10+
- Create a virtual environment
- Install key packages: openai, langchain, jupyter, fastapi, python-dotenv
- Set up API keys for OpenAI/Azure OpenAI

### Task 2: Basic LLM Interaction
- Write a script to interact with OpenAI's GPT models
- Experiment with different models (GPT-3.5 vs GPT-4)
- Measure token usage and costs
- Compare responses across different models (OpenAI, Claude, DeepSeek)

### Task 3: Prompt Engineering Workshop
- Create effective prompts using:
  - One-shot learning
  - Few-shot learning
  - Chain-of-thought prompting
  - Create a prompt template system
- Document your findings on what makes prompts effective

### Task 4: Build a Simple Chatbot
- Create a command-line chatbot using OpenAI
- Implement conversation history (memory)
- Add system instructions to guide the assistant's behavior
- Test the chatbot with various user queries

### Task 5: Function Calling & Tool Use
- Implement function calling with LLMs
- Extract structured data from text
- Build a calculator bot that can solve math problems
- Create a weather bot that determines location from user input

### Task 6: Embeddings Exploration
- Generate embeddings for various texts
- Calculate similarity between embeddings
- Build a simple semantic search system
- Visualize embeddings using dimensionality reduction

## Resources
- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference)
- [LangChain Documentation](https://python.langchain.com/docs/get_started/introduction)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
